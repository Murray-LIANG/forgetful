<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sharding on Forgetful :/</title>
    <link>https://murray-liang.github.io/forgetful/tags/sharding/</link>
    <description>Recent content in sharding on Forgetful :/</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Mon, 10 Feb 2020 16:37:31 +0800</lastBuildDate>
    
	<atom:link href="https://murray-liang.github.io/forgetful/tags/sharding/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Distributed</title>
      <link>https://murray-liang.github.io/forgetful/2020/02/distributed/</link>
      <pubDate>Mon, 10 Feb 2020 16:37:31 +0800</pubDate>
      
      <guid>https://murray-liang.github.io/forgetful/2020/02/distributed/</guid>
      <description>Partitioning / Sharding github.com/Murray-LIANG/nodering
Distributed Lock  Could use etcd as backend. Some implementation: https://github.com/etcd-io/etcd/blob/master/clientv3/concurrency/mutex.go If two clients request to lock at the same time, the later client would change the value of same key in etcd3 but with new revision. The lock logic needs to wait for old revision deletion which means the older lock is released. To make sure locks released even when clients crash, use expiration on the key.</description>
    </item>
    
    <item>
      <title>Sharding Pinterest</title>
      <link>https://murray-liang.github.io/forgetful/2020/02/sharding-pinterest/</link>
      <pubDate>Mon, 10 Feb 2020 16:37:31 +0800</pubDate>
      
      <guid>https://murray-liang.github.io/forgetful/2020/02/sharding-pinterest/</guid>
      <description>Note of https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f
Feature Required  Create Pins. Like other Pins. Follow other Pinners. View a home feed of all the Pinners he/she follows. Support asking for N number of Pins in a board in a deterministic order (such as reverse creation time or user specified ordering).  Scale Required 50M Pins have been saved by Pinners onto 1B boards.
Design Goals  Stable and high available. Low latency. Eventually consistency.</description>
    </item>
    
    <item>
      <title>Sharding Pinterest: How We Scaled Our MySQL Fleet</title>
      <link>https://murray-liang.github.io/forgetful/2020/02/design-sharding-pinterest/</link>
      <pubDate>Mon, 10 Feb 2020 16:37:31 +0800</pubDate>
      
      <guid>https://murray-liang.github.io/forgetful/2020/02/design-sharding-pinterest/</guid>
      <description>https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f
TODO</description>
    </item>
    
    <item>
      <title>System Design Topics</title>
      <link>https://murray-liang.github.io/forgetful/2020/02/design-topics/</link>
      <pubDate>Mon, 10 Feb 2020 16:37:31 +0800</pubDate>
      
      <guid>https://murray-liang.github.io/forgetful/2020/02/design-topics/</guid>
      <description>Some high-level trade-offs  Performance vs scalability Latency vs throughput Availability vs consistency  Keep in mind that everything is a trade-off.
Performance vs scalability A service is scalable if it results in increased performance in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.
Many algorithms that perform reasonably well under low load and small datasets can explode in cost if either requests rates increase, the dataset grows or the number of nodes in the distributed system increases.</description>
    </item>
    
  </channel>
</rss>